---
title: "Sample Project"
subtitle: "MKTG - LEE"
execute: 
  echo: true
  eval: true
format:
  html:
    code-fold: false
    self-contained: true
jupyter: python3
---


# Executive Summary

# Introduction & Data Set Used

- We study the automobile industry because ...
- The data set we analyze comes from ..., and the files can be accessed through [Kaggle](https://kaggle.com)




# Data Preprocessing and Exploratory Data Analysis

- We explore the data set by visualizing the main variables of interest...

```{python}
# load required packages
import polars as pl
import plotly.express as px

# Load data
df = pl.read_csv("https://raw.githubusercontent.com/VroomVroomMKTG6234/repo/refs/heads/main/car_prices.csv")

# View the first few rows of the data
df.head()

```


- First, we examine the distribution of 'sellingprice' by plotting a histogram.

```{python}

px.histogram(df, x = 'sellingprice')


```


From the histogram, it looks like the range of the avg_distance traveled is mostly between 200 and 800 mpg.

```{python}
num_columns = df.width
print("Number of variables:", num_columns)
```
#In this dataset, we have 16 columns

```{python}
for col in df.columns:
    unique_count = df[col].n_unique()
    print(f"{col}: {unique_count} unique values")
```
#Determining how many different categories are in each column

```{python}
aggregations = []
for col in df.columns:
    if df.schema[col] in [pl.Float64, pl.Float32, pl.Int64, pl.Int32]:
        aggregations.extend([
            pl.col(col).mean().alias(f"{col}_mean"),
            pl.col(col).median().alias(f"{col}_median"),
            pl.col(col).var().alias(f"{col}_variance"),
            pl.col(col).std().alias(f"{col}_std")
        ])
summary_stats = df.select(aggregations)
print(summary_stats)
#summary statistics for only numeric columns
```

```{python}
px.histogram(
  df,
  x = "odometer"
)
px.histogram(
  df,
  x ="condition"
)
px.histogram(
  df,
  x ="sellingprice"
)
px.histogram(
  df,
  x = "mmr"
)    
#plotting of each numerical variable using a histogram, seperate out code to run, just have them all together for organization
```

```{python}
px.bar(
  df,
  x = "body",
  y = "sellingprice"
)
#plotting of each categorical variable using a bar chart, still need to add more!
```

- Second, we examine some summary statistics of the avg_distance variable:

```{python}
#| echo: false

# This will only show the results but not the code, because 'echo' is set to false
email.select(
  pl.col("avg_distance").mean().alias("mean_avg_distance"),
  pl.col("avg_distance").max().alias("max_avg_distance"),
  pl.col("avg_distance").min().alias("min_avg_distance"),
)

```


# Model-Based Analysis

We use XXX model to investigate the data set.


## Customer Segmentation
```{python}
# load required packages
import polars as pl
import plotly.express as px
from sklearn.pipeline import Pipeline
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import numpy as np

# Load data
df = pl.read_csv("https://raw.githubusercontent.com/VroomVroomMKTG6234/repo/refs/heads/main/car_prices.csv")

# View the first few rows of the data

df.head()
```



```{python}
# Select relevant features for clustering

df_bases = df.select([
    'sellingprice',
    'year',
    'condition',
    'odometer',])

df_bases = df_bases.drop_nulls()


```


```{python}

def create_pipeline(num_clusters, random_seed = 42):
    """
    Creates a machine learning pipeline with a scaler and KMeans.
    """
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('kmeans', KMeans(n_clusters=num_clusters, random_state=random_seed))
    ])
    return pipeline


```


```{python}
def calculate_totwithinss(data, k):
    kmeans_pipeline = create_pipeline(k, random_seed=10)
    kmeans_pipeline.fit(data)
    return kmeans_pipeline['kmeans'].inertia_ # inertia is average

# Calculate tot.withinss for different values of k (Average difference)
k_values = range(1, 10) # 10 is Exclusive, so it stops at 9. Starts at 1
totwithinss_values = [calculate_totwithinss(df_bases, k) for k in k_values]

# Create a DataFrame for results
kmeans_results = pl.DataFrame(
    {'num_clusters': k_values,
     'tot_withinss': totwithinss_values})

# Plot the elbow method using Plotly Express
elbow_plot = px.line(
    data_frame = kmeans_results,
    x = 'num_clusters',
    y = 'tot_withinss', 
    markers = True,
    labels = {
        'num_clusters': 'Number of Clusters', 'tot_withinss': 'Total Within SS'
        },
    title = 'Elbow Method for Optimal k')

elbow_plot.show()
```


```{python}
# Choose the number of clusters based on the elbow method
optimal_k = 2

# Run K-means clustering

df_kmeans_pipeline = create_pipeline(optimal_k)
df_kmeans_pipeline.fit(df_bases)


# Add cluster assignments to the original data
df_bases_with_clusters = df_bases.with_columns(
    pl.Series(
        "segment_number",
        df_kmeans_pipeline['kmeans'].labels_ + 1 # + 1 adds to make the clusters 1,2,3 instead of 0,1,2
        ).cast(pl.Utf8).cast(pl.Categorical)  # Make cluster labels 1-indexed, the casting is optional, used to change to string and then to categorical data
)

df_bases_with_clusters.head()

# for col in df.columns:
#    means[col] = df[col].mean()

df_bases_grouped = df_bases_with_clusters.group_by('segment_number').agg(pl.col('sellingprice').mean(),pl.col('year').mean(),pl.col('odometer').mean(),pl.col('condition').mean())

print(df_bases_grouped)
```

Description of Each Segment

As displayed in the "df_bases_grouped" table, we have created two distinct segments that separate the records in the cars_prices.csv file. Using the 'sellingprice', 'year', 'odometer', and 'condition' attribtutes, we created an elbow plot, and determined 2 clusters was the optimal number of segments to cluster the data. Using the k-means cluster analysis, we created a k-means model and grouped the data by the 'segment_number'. We calculated the mean of each column intially included in the elbow plot, and found distinct difference in each segement. In the first segment '1', we exhibited higher priced vehicles were consolidated, with a younger year of manufacture, lower odometer, and higher condition value. Alternatively, the segment '2' exhibited lower priced vehicles, a older year of manufacture, a higher odometer, and a lower condition value. This leads us to conclude that segment '1' contains nicer vehicles that are less used, and segment '2' contains lower quality vehicles that are more used. 

## Targeting

## Binary Outcome Prediction

## Continuous Outcome Prediction

## RFM Analysis

## ROMI Analysis

# Results and Findings

# Research Implications
## Managerical Recommendations
1.
2.
3.

## Actionable Plans
1.
2.
3.

# Conclusion

## Works Cited